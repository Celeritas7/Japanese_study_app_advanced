#!/usr/bin/env python3
"""
JLPT Kanji Data Parser
======================
Parses:
1. Kanji_Story_database_R002.xlsm ‚Üí story CSVs
2. kanjidic2.xml ‚Üí similar kanji groups CSV

Output files:
- japanese_kanji_story_groups.csv
- japanese_kanji_stories.csv
- japanese_kanji_similar_groups.csv

Usage:
1. Place this script in the same folder as:
   - Kanji_Story_database_R002.xlsm
   - kanjidic2.xml
   
2. Install dependencies:
   pip install pandas openpyxl lxml

3. Run:
   python kanji_parser.py
"""

import pandas as pd
import xml.etree.ElementTree as ET
from collections import defaultdict
import csv
import os
import re

# ============================================
# CONFIGURATION
# ============================================
EXCEL_FILE = "Kanji_Story_database_R002.xlsm"
KANJIDIC_FILE = "kanjidic2.xml"
JMDICT_FILE = "JMdict_e.xml"  # Optional

OUTPUT_DIR = "output_csv"

# ============================================
# HELPER FUNCTIONS
# ============================================
def clean_text(text):
    """Clean and normalize text"""
    if pd.isna(text) or text is None:
        return ""
    return str(text).strip()

def extract_frame_number(story_text):
    """Extract frame number like [8] from story text"""
    if not story_text:
        return ""
    match = re.search(r'\[(\d+)\]', story_text)
    return match.group(1) if match else ""

def is_kanji(char):
    """Check if character is a kanji"""
    if not char:
        return False
    code = ord(char[0])
    return (0x4E00 <= code <= 0x9FFF or  # CJK Unified Ideographs
            0x3400 <= code <= 0x4DBF or  # CJK Extension A
            0x20000 <= code <= 0x2A6DF)  # CJK Extension B

# ============================================
# PART 1: PARSE EXCEL STORY DATABASE
# ============================================
def parse_excel_stories(excel_path):
    """
    Parse the Story_all sheet from Excel file
    
    Column mapping (based on analysis):
    - Col 2: Group number
    - Col 3: Group kanji
    - Col 4: Member number within group
    - Col 5: Member kanji (if different from group)
    - Col 13: Display kanji
    - Col 14: Meaning
    - Col 15: Story text
    - Col 17: On'yomi
    """
    print(f"\nüìñ Parsing Excel file: {excel_path}")
    
    try:
        df = pd.read_excel(excel_path, sheet_name='Story_all', header=None)
        print(f"   Loaded {len(df)} rows")
    except Exception as e:
        print(f"   ‚ùå Error loading Excel: {e}")
        return [], []
    
    groups = {}  # group_kanji -> group data
    stories = []  # individual kanji stories
    
    for idx, row in df.iterrows():
        # Skip header/empty rows
        if pd.isna(row[3]) or str(row[3]).strip() == '' or str(row[3]) == 'Kanji_sequence':
            continue
        
        group_num = row[2] if not pd.isna(row[2]) else None
        group_kanji = clean_text(row[3])
        member_num = row[4] if not pd.isna(row[4]) else 1
        member_kanji = clean_text(row[5]) if not pd.isna(row[5]) else ""
        display_kanji = clean_text(row[13])
        meaning = clean_text(row[14])
        story = clean_text(row[15])
        onyomi = clean_text(row[17])
        
        # Determine the actual kanji for this entry
        actual_kanji = display_kanji or member_kanji or group_kanji
        
        if not actual_kanji or not is_kanji(actual_kanji[0]):
            continue
        
        # Extract frame number from story
        frame_num = extract_frame_number(story)
        
        # If this is the first entry for this group (member_num == 1), save as group
        if member_num == 1 or group_kanji not in groups:
            groups[group_kanji] = {
                'group_number': group_num,
                'group_kanji': group_kanji,
                'group_meaning': meaning,
                'group_story': story,
                'onyomi': onyomi
            }
        
        # Add individual story entry
        stories.append({
            'group_kanji': group_kanji,
            'member_number': member_num,
            'kanji': actual_kanji,
            'meaning': meaning,
            'story': story,
            'frame_number': frame_num,
            'onyomi': onyomi
        })
    
    # Handle duplicate kanji by adding suffixes ‚ë†‚ë°‚ë¢...
    stories = add_duplicate_suffixes(stories)
    
    print(f"   ‚úÖ Found {len(groups)} groups, {len(stories)} stories")
    return list(groups.values()), stories


def add_duplicate_suffixes(stories):
    """
    Add suffixes ‚ë†‚ë°‚ë¢... to duplicate kanji entries.
    First occurrence keeps original, subsequent get ‚ë†‚ë°‚ë¢...
    """
    # Japanese circled numbers
    circled_numbers = ['‚ë†', '‚ë°', '‚ë¢', '‚ë£', '‚ë§', '‚ë•', '‚ë¶', '‚ëß', '‚ë®', '‚ë©',
                       '‚ë™', '‚ë´', '‚ë¨', '‚ë≠', '‚ëÆ', '‚ëØ', '‚ë∞', '‚ë±', '‚ë≤', '‚ë≥']
    
    # Count occurrences of each kanji
    kanji_count = {}
    for story in stories:
        kanji = story['kanji']
        if kanji not in kanji_count:
            kanji_count[kanji] = 0
        kanji_count[kanji] += 1
    
    # Find kanji with duplicates
    duplicates = {k: v for k, v in kanji_count.items() if v > 1}
    print(f"   ‚ÑπÔ∏è Found {len(duplicates)} kanji with multiple entries")
    
    # Track current index for each duplicate kanji
    kanji_index = {k: 0 for k in duplicates}
    
    # Add suffixes
    result = []
    for story in stories:
        kanji = story['kanji']
        
        if kanji in duplicates:
            idx = kanji_index[kanji]
            if idx < len(circled_numbers):
                suffix = circled_numbers[idx]
            else:
                suffix = f"({idx + 1})"  # Fallback for >20 duplicates
            
            # Create new entry with suffixed kanji
            new_story = story.copy()
            new_story['kanji'] = kanji + suffix
            new_story['original_kanji'] = kanji  # Keep original for reference
            result.append(new_story)
            
            kanji_index[kanji] += 1
        else:
            story['original_kanji'] = story['kanji']  # Same as kanji
            result.append(story)
    
    return result

# ============================================
# PART 2: PARSE KANJIDIC2 XML
# ============================================
def parse_kanjidic2(xml_path):
    """
    Parse KANJIDIC2 XML file for:
    - Radical information
    - On'yomi readings
    - Kun'yomi readings
    - Stroke count
    """
    print(f"\nüìö Parsing KANJIDIC2: {xml_path}")
    
    if not os.path.exists(xml_path):
        print(f"   ‚ö†Ô∏è File not found: {xml_path}")
        print("   Skipping KANJIDIC2 parsing...")
        return {}
    
    kanji_data = {}
    
    try:
        # Parse XML (this may take a moment for large files)
        print("   Loading XML (this may take a moment)...")
        tree = ET.parse(xml_path)
        root = tree.getroot()
        
        for character in root.findall('character'):
            literal = character.find('literal')
            if literal is None:
                continue
            
            kanji = literal.text
            
            # Get radical
            radical = ""
            rad_elem = character.find('.//rad_value[@rad_type="classical"]')
            if rad_elem is not None:
                radical = rad_elem.text
            
            # Get readings
            onyomi_list = []
            kunyomi_list = []
            
            for reading in character.findall('.//reading'):
                r_type = reading.get('r_type')
                if r_type == 'ja_on':
                    onyomi_list.append(reading.text)
                elif r_type == 'ja_kun':
                    kunyomi_list.append(reading.text)
            
            # Get meanings (English)
            meanings = []
            for meaning in character.findall('.//meaning'):
                if meaning.get('m_lang') is None:  # English has no lang attr
                    meanings.append(meaning.text)
            
            # Get stroke count
            stroke_count = ""
            stroke_elem = character.find('.//stroke_count')
            if stroke_elem is not None:
                stroke_count = stroke_elem.text
            
            # Get grade/JLPT level
            grade = ""
            grade_elem = character.find('.//grade')
            if grade_elem is not None:
                grade = grade_elem.text
            
            kanji_data[kanji] = {
                'kanji': kanji,
                'radical': radical,
                'onyomi': '„ÄÅ'.join(onyomi_list),
                'kunyomi': '„ÄÅ'.join(kunyomi_list),
                'meanings': ', '.join(meanings[:3]),  # First 3 meanings
                'stroke_count': stroke_count,
                'grade': grade
            }
        
        print(f"   ‚úÖ Parsed {len(kanji_data)} kanji entries")
        
    except ET.ParseError as e:
        print(f"   ‚ùå XML Parse error: {e}")
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
    
    return kanji_data

def generate_similar_groups(kanji_data):
    """
    Generate similar kanji groups based on:
    1. Same radical
    2. Same On'yomi reading
    3. Same Kun'yomi reading
    """
    print("\nüîó Generating similar kanji groups...")
    
    groups = []
    
    # Group by radical
    radical_groups = defaultdict(list)
    for kanji, data in kanji_data.items():
        if data['radical']:
            radical_groups[data['radical']].append(kanji)
    
    # Radical names (common ones)
    radical_names = {
        '1': '‰∏Ä („ÅÑ„Å°)', '2': '‰∏® („Åº„ÅÜ)', '3': '‰∏∂ („Å¶„Çì)', '4': '‰∏ø („ÅÆ)',
        '5': '‰πô („Åä„Å§)', '6': '‰∫Ö („Åã„Åé)', '7': '‰∫å („Å´)', '8': '‰∫† („Å™„Åπ„Å∂„Åü)',
        '9': '‰∫∫/‰∫ª („Å≤„Å®)', '10': 'ÂÑø („Å´„Çì„Å´„Çá„ÅÜ)', '11': 'ÂÖ• („ÅÑ„Çã)',
        '12': 'ÂÖ´ („ÅØ„Å°)', '13': 'ÂÜÇ („Åë„ÅÑ„Åå„Åæ„Åà)', '14': 'ÂÜñ („Çè„Åã„Çì„ÇÄ„Çä)',
        '15': 'ÂÜ´ („Å´„Åô„ÅÑ)', '16': 'Âá† („Å§„Åè„Åà)', '17': 'Âáµ („Åã„Çì„Å´„Çá„ÅÜ)',
        '18': 'ÂàÄ/ÂàÇ („Åã„Åü„Å™)', '19': 'Âäõ („Å°„Åã„Çâ)', '20': 'Âãπ („Å§„Å§„Åø„Åå„Åæ„Åà)',
        '30': 'Âè£ („Åè„Å°)', '32': 'Âúü („Å§„Å°)', '37': 'Â§ß („Å†„ÅÑ)',
        '38': 'Â•≥ („Åä„Çì„Å™)', '40': 'ÂÆÄ („ÅÜ„Åã„Çì„ÇÄ„Çä)', '46': 'Â±± („ÇÑ„Åæ)',
        '57': 'Âºì („ÇÜ„Åø)', '60': 'ÂΩ≥ („Åé„Çá„ÅÜ„Å´„Çì„Åπ„Çì)', '61': 'ÂøÉ/ÂøÑ („Åì„Åì„Çç)',
        '64': 'Êâã/Êâå („Å¶)', '72': 'Êó• („Å≤)', '74': 'Êúà („Å§„Åç/„Å´„Åè„Å•„Åç)',
        '75': 'Êú® („Åç)', '85': 'Ê∞¥/Ê∞µ („Åø„Åö)', '86': 'ÁÅ´/ÁÅ¨ („Å≤)',
        '94': 'Áä¨/Áä≠ („ÅÑ„Å¨)', '96': 'Áéâ/Áéã („Åü„Åæ)', '102': 'Áî∞ („Åü)',
        '109': 'ÁõÆ („ÇÅ)', '112': 'Áü≥ („ÅÑ„Åó)', '113': 'Á§∫/Á§ª („Åó„ÇÅ„Åô)',
        '115': 'Á¶æ („ÅÆ„Åé)', '118': 'Á´π („Åü„Åë)', '120': 'Á≥∏ („ÅÑ„Å®)',
        '130': 'ËÇâ/Êúà („Å´„Åè)', '140': 'Ëâ∏/Ëâπ („Åè„Åï)', '142': 'Ëô´ („ÇÄ„Åó)',
        '145': 'Ë°£/Ë°§ („Åì„Çç„ÇÇ)', '149': 'Ë®Ä/Ë®Å („Åì„Å®„Å∞)', '154': 'Ë≤ù („Åã„ÅÑ)',
        '157': 'Ë∂≥ („ÅÇ„Åó)', '162': 'Ëæµ/Ëæ∂ („Åó„Çì„Å´„Çá„ÅÜ)', '167': 'Èáë/Èáí („Åã„Å≠)',
        '169': 'ÈñÄ („ÇÇ„Çì)', '170': 'ÈòùÂ∑¶ („Åì„Åñ„Å®)', '172': 'Èöπ („Åµ„Çã„Å®„Çä)',
        '173': 'Èõ® („ÅÇ„ÇÅ)', '184': 'È£ü/È£† („Åó„Çá„Åè)', '187': 'È¶¨ („ÅÜ„Åæ)',
        '195': 'È≠ö („ÅÜ„Åä)', '196': 'È≥• („Å®„Çä)'
    }
    
    for radical, kanji_list in radical_groups.items():
        if len(kanji_list) >= 2:  # Only groups with 2+ kanji
            radical_name = radical_names.get(radical, f"Radical {radical}")
            groups.append({
                'group_type': 'radical',
                'group_key': radical,
                'group_name': radical_name,
                'kanji_list': ','.join(kanji_list),
                'kanji_count': len(kanji_list)
            })
    
    # Group by On'yomi
    onyomi_groups = defaultdict(list)
    for kanji, data in kanji_data.items():
        if data['onyomi']:
            # Get first on'yomi reading
            first_on = data['onyomi'].split('„ÄÅ')[0].strip()
            if first_on:
                onyomi_groups[first_on].append(kanji)
    
    for reading, kanji_list in onyomi_groups.items():
        if len(kanji_list) >= 3:  # Only groups with 3+ kanji
            groups.append({
                'group_type': 'onyomi',
                'group_key': reading,
                'group_name': f"Èü≥Ë™≠„Åø: {reading}",
                'kanji_list': ','.join(kanji_list),
                'kanji_count': len(kanji_list)
            })
    
    # Group by Kun'yomi (first reading only)
    kunyomi_groups = defaultdict(list)
    for kanji, data in kanji_data.items():
        if data['kunyomi']:
            # Get first kun'yomi, remove okurigana marker
            first_kun = data['kunyomi'].split('„ÄÅ')[0].split('.')[0].strip()
            if first_kun and len(first_kun) >= 2:  # At least 2 characters
                kunyomi_groups[first_kun].append(kanji)
    
    for reading, kanji_list in kunyomi_groups.items():
        if len(kanji_list) >= 3:
            groups.append({
                'group_type': 'kunyomi',
                'group_key': reading,
                'group_name': f"Ë®ìË™≠„Åø: {reading}",
                'kanji_list': ','.join(kanji_list),
                'kanji_count': len(kanji_list)
            })
    
    print(f"   ‚úÖ Generated {len(groups)} similar groups")
    print(f"      - Radical groups: {len([g for g in groups if g['group_type'] == 'radical'])}")
    print(f"      - On'yomi groups: {len([g for g in groups if g['group_type'] == 'onyomi'])}")
    print(f"      - Kun'yomi groups: {len([g for g in groups if g['group_type'] == 'kunyomi'])}")
    
    return groups

# ============================================
# PART 3: WRITE CSV FILES
# ============================================
def write_csv(data, filename, fieldnames):
    """Write data to CSV file"""
    filepath = os.path.join(OUTPUT_DIR, filename)
    
    with open(filepath, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for row in data:
            # Ensure all fields exist
            clean_row = {k: row.get(k, '') for k in fieldnames}
            writer.writerow(clean_row)
    
    print(f"   üìÅ Written: {filepath} ({len(data)} rows)")

# ============================================
# MAIN EXECUTION
# ============================================
def main():
    print("=" * 60)
    print("JLPT Kanji Data Parser")
    print("=" * 60)
    
    # Create output directory
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"\nüìÇ Output directory: {OUTPUT_DIR}/")
    
    # ---- PART 1: Parse Excel Stories ----
    if os.path.exists(EXCEL_FILE):
        groups, stories = parse_excel_stories(EXCEL_FILE)
        
        if groups:
            write_csv(
                groups,
                'japanese_kanji_story_groups.csv',
                ['group_number', 'group_kanji', 'group_meaning', 'group_story', 'onyomi']
            )
        
        if stories:
            write_csv(
                stories,
                'japanese_kanji_stories.csv',
                ['group_kanji', 'member_number', 'kanji', 'original_kanji', 'meaning', 'story', 'frame_number', 'onyomi']
            )
    else:
        print(f"\n‚ö†Ô∏è Excel file not found: {EXCEL_FILE}")
    
    # ---- PART 2: Parse KANJIDIC2 ----
    kanji_data = parse_kanjidic2(KANJIDIC_FILE)
    
    if kanji_data:
        similar_groups = generate_similar_groups(kanji_data)
        
        if similar_groups:
            write_csv(
                similar_groups,
                'japanese_kanji_similar_groups.csv',
                ['group_type', 'group_key', 'group_name', 'kanji_list', 'kanji_count']
            )
    
    # ---- Summary ----
    print("\n" + "=" * 60)
    print("‚úÖ PARSING COMPLETE!")
    print("=" * 60)
    print(f"\nOutput files in '{OUTPUT_DIR}/' folder:")
    print("  1. japanese_kanji_story_groups.csv  ‚Üí Upload to japanese_kanji_story_groups")
    print("  2. japanese_kanji_stories.csv       ‚Üí Upload to japanese_kanji_stories")
    print("  3. japanese_kanji_similar_groups.csv ‚Üí Upload to japanese_kanji_similar_groups")
    print("\nNext steps:")
    print("  1. Go to Supabase Dashboard ‚Üí Table Editor")
    print("  2. Select each table ‚Üí Import CSV")
    print("  3. Upload the corresponding CSV file")
    print("\n" + "=" * 60)

if __name__ == '__main__':
    main()
